{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inList(array , dictionary):\n",
    "    for lval in array:\n",
    "        for key, val in dictionary.items():\n",
    "               for v in val:\n",
    "                    if v in lval:\n",
    "                          return key\n",
    "                        \n",
    "def mapDegInfo(array):\n",
    "    if len(array) % 2 > 2:\n",
    "        return 'Magistrale'\n",
    "    else:\n",
    "        return 'Triennale'\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are to accessories functions that i defined in order to scrape some extra contents out of the ones that i already accessed by processing html elements reading their text. In particular the first one that will be used as well in further chuncks of code, just loops over a list of elements and for each key value pairs of a dictionary whose values are lists, it checks wether an element of dictionary's values is contained and thus maps it with the corresponding key. In this case it is used in order to assign a degree type such as Master's, Bachelor's or P.h.d. MapDegInfo is used for all of those fields where the user did not enter the type of degree associated, basically it fetches the number of education fields inferring the type based on the number of fields fetched. To make it simple it is based on the assumption that if more than two fields are entered in education field, suppose a high school title and a bachelor's deegree, the functions asserts that if there is another field entered it must be a Master's deegree.       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[['Training Specialist', 'Training Specialist', 'Legal Assistant Paralegal', 'Legal Affairs Specialist'], ['Master di I livello', 'Politiche di Sicurezza e Polizie Locali', 'Laurea Magistrale  LM in Giurisprudenza', 'Ragioniere perito commerciale - programmatore'], 'Magistrale', ['2015', '2009', '2014', '2004', '2009']], [[\"Esperienze di Lavoro all'Estero come Care Assistant,Barman,Waiter\"], ['Scienze Politiche,Sociali ed Internazionali', 'Curriculum Sociologia', 'Diploma', 'Liceo Scientifico'], 'Triennale', ['2014', '2016', '2006', '2011']], [['docente di lettere', 'docente di lettere', 'docente di lettere', 'docente di lettere', 'docente di lettere', 'Studente tirocinante'], ['Laurea Magistrale  LM in Scienze Umanistiche', 'Italianistica', '110 e lode', 'Arts and Humanities', 'Laurea triennale in Scienze Umanistiche', 'lettere moderne', '110'], 'Magistrale', ['2017', '2020', '2016', '2017', '2014', '2017']], [['Junior Software Developer', 'Promoter vendite', 'Promoter vendite', 'Scuola lavoro'], ['Laurea triennale', 'Ingegneria informatica', '86/110'], 'Triennale', ['2016', '2021']], [['IoT Edge Developer', 'Sviluppatore front-end'], ['Laurea Magistrale  LM', 'Ingegneria informatica', '110 e lode', 'Laurea triennale', 'Ingegneria informatica', '109', 'Diploma Istituto Tecnico', 'Perito informatico', '88'], 'Magistrale', ['2019', '2020', '2015', '2018', '2010', '2015']]]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import csv\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "files = os.listdir(\".\")\n",
    "\n",
    "experiences = []\n",
    "educations = []\n",
    "degInfos = []\n",
    "\n",
    "profiles = []\n",
    "\n",
    "degreeInfo = {\n",
    "    'Dottorato': ['Dottorato', 'Phd','PhD','PHD', 'P.h.D', 'P.h.d','P.H.D'],\n",
    "    'Magistrale': ['Magistrale','magistrale','specialistica','Specialistica',\"Master's\",\"master's\"],\n",
    "    'Triennale': ['Triennale',\"Bachelor's\",'triennale']\n",
    "}\n",
    "\n",
    "tag = ['h3', 'span']\n",
    "classes = ['education__item education__item--degree-info','pv-entity__comma-item','pv-entity__school-name t-16 t-black t-bold', 't-16 t-black t-bold','profile-section-card__title']\n",
    "\n",
    "for f in files:\n",
    "    if f.endswith(\".html\"):\n",
    "        with open(f, encoding='utf-8') as fp:\n",
    "            soup = BeautifulSoup(fp)\n",
    "            regex = re.compile('.*experience.*')\n",
    "            experienceSection = soup.find('section', {'class':regex})\n",
    "            for el in experienceSection.find_all('span', {'class':'visually-hidden'}): el.decompose()\n",
    "            experienceTags = (experienceSection.find_all(t, {'class': c}) for t in tag for c in classes)\n",
    "            expText = next((exp for exp in experienceTags if len(exp) > 0), \"\")\n",
    "            experience = [el.get_text().strip() for el in expText if el != \"\"]\n",
    "            regexEd = re.compile('.*education.*')\n",
    "            educationSection = soup.find('section', {'class':regexEd})\n",
    "            educationTags = (educationSection.find_all(tag[1], {'class':c}) for c in classes)\n",
    "            edText = next((ed for ed in educationTags if len(ed) > 0), \"\")\n",
    "            education = [el.get_text().strip() for el in edText if el != \"\"]\n",
    "            educationTimes = [el.get_text() for el in educationSection.find_all('time')]\n",
    "            infoDeg = inList(education, degreeInfo) if inList(education, degreeInfo) is not None else mapDegInfo(education)\n",
    "            profiles.append([experience, education, infoDeg, educationTimes])\n",
    "\n",
    "print(profiles[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this first huge part of code above i built a scraper almost from scratch using Beautiful Soup which is a python library i used to pull out data from the html files of linkedin profiles i manually downloaded in the current local directory. In a nutshell what i did was looping over almost 500 profiles pages donwloaded from LinkedIn and for each file i extracted those element of interest in order to fatch data from education and work section. In order to do that i queried the significant html element by tag name and class name saving the text data i needed into a list of lists in order to write them into a csv file for persistency and then loading them into pandas df for the manipulation.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loggin into a .csv file\n",
    "\n",
    "import csv\n",
    "\n",
    "header = ['Job','Education','infoDeg','dateRange']\n",
    "\n",
    "csv_file = 'linkedin_profiles2.csv'\n",
    "with open(csv_file, 'w', newline='') as fp:\n",
    "    writer = csv.writer(fp)\n",
    "    writer.writerow(header)\n",
    "    writer.writerows(profiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job</th>\n",
       "      <th>Education</th>\n",
       "      <th>infoDeg</th>\n",
       "      <th>dateRange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['Training Specialist', 'Training Specialist',...</td>\n",
       "      <td>['Master di I livello', 'Politiche di Sicurezz...</td>\n",
       "      <td>Magistrale</td>\n",
       "      <td>['2015', '2009', '2014', '2004', '2009']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[\"Esperienze di Lavoro all'Estero come Care As...</td>\n",
       "      <td>['Scienze Politiche,Sociali ed Internazionali'...</td>\n",
       "      <td>Triennale</td>\n",
       "      <td>['2014', '2016', '2006', '2011']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['docente di lettere', 'docente di lettere', '...</td>\n",
       "      <td>['Laurea Magistrale  LM in Scienze Umanistiche...</td>\n",
       "      <td>Magistrale</td>\n",
       "      <td>['2017', '2020', '2016', '2017', '2014', '2017']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['Junior Software Developer', 'Promoter vendit...</td>\n",
       "      <td>['Laurea triennale', 'Ingegneria informatica',...</td>\n",
       "      <td>Triennale</td>\n",
       "      <td>['2016', '2021']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['IoT Edge Developer', 'Sviluppatore front-end']</td>\n",
       "      <td>['Laurea Magistrale  LM', 'Ingegneria informat...</td>\n",
       "      <td>Magistrale</td>\n",
       "      <td>['2019', '2020', '2015', '2018', '2010', '2015']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Job  \\\n",
       "0  ['Training Specialist', 'Training Specialist',...   \n",
       "1  [\"Esperienze di Lavoro all'Estero come Care As...   \n",
       "2  ['docente di lettere', 'docente di lettere', '...   \n",
       "3  ['Junior Software Developer', 'Promoter vendit...   \n",
       "4   ['IoT Edge Developer', 'Sviluppatore front-end']   \n",
       "\n",
       "                                           Education     infoDeg  \\\n",
       "0  ['Master di I livello', 'Politiche di Sicurezz...  Magistrale   \n",
       "1  ['Scienze Politiche,Sociali ed Internazionali'...   Triennale   \n",
       "2  ['Laurea Magistrale  LM in Scienze Umanistiche...  Magistrale   \n",
       "3  ['Laurea triennale', 'Ingegneria informatica',...   Triennale   \n",
       "4  ['Laurea Magistrale  LM', 'Ingegneria informat...  Magistrale   \n",
       "\n",
       "                                          dateRange  \n",
       "0          ['2015', '2009', '2014', '2004', '2009']  \n",
       "1                  ['2014', '2016', '2006', '2011']  \n",
       "2  ['2017', '2020', '2016', '2017', '2014', '2017']  \n",
       "3                                  ['2016', '2021']  \n",
       "4  ['2019', '2020', '2015', '2018', '2010', '2015']  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reporting data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('linkedin_profiles2.csv', encoding='ISO-8859-1')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Job          object\n",
       "Education    object\n",
       "infoDeg      object\n",
       "dateRange    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the dataset, whose first elements are showcased by the head() method of pandas library, does still contain data that are a bit raw. Indeed, the columns displayed incapsulate inside lists all of those data scraped from html pages of linkedin profile such as all jobs registered in the experience section, all education information that could go from high school to P.h.d degrees and each enrollment and graduation date related to each education title entered. From this first sight at data it appears to me that this dataset needs to be modified a bit in order to keep just the information of interest for this work such as the last (most significant) education titles among P.h.D, bachelor or master degrees from University of Bologna, the last job inserted in the list of jobs and the last date range involving enrollment and graduation date of the associated degree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(496, 4)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from ast import literal_eval\n",
    "\n",
    "df.Job = df.Job.apply(literal_eval)\n",
    "df.Education = df.Education.apply(literal_eval)\n",
    "df.dateRange = df.dateRange.apply(literal_eval) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in the cell above, since data fetched from the csv file containing linkedin profiles previously stored in arrays are perceived as one big string i applied a function in order to split those string back into the two lists of job, education and date range.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Risorse umane': ['Responsabile Area Espansione', 'Senior Recruitment Officer', 'Analista Direzione Sviluppo Persone e Organizzazione', 'Training Specialist', 'HR'], 'Ristorazione': ['Assistente enologo', 'Barman', 'barista']}\n",
      "{'Giurisprudenza': ['Giurisprudenza'], 'Scienze della comunicazione': ['Semiotica', 'Marketing', 'PubblicitÃ\\xa0', 'Communication', 'Comunicazione', 'comunicazione', \"comunicazione pubblica, d'impresa e pubblicitÃ\\xa0\", 'Mass media e Politica', 'Brand Strategy and Marketing', 'Scienze della comunicazione', 'Comunicazione e Digital Media', 'Scienze della Comunicazione', 'Comunicazione']}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "jobWrapperFile = 'jobWrapper.json'\n",
    "educationWrapperFile = 'educationWrapper.json'\n",
    "\n",
    "jobWrapper = {}\n",
    "educationWrapper = {} \n",
    "\n",
    "with open(jobWrapperFile) as json_job_wrapper:\n",
    "    jobWrapper = json.load(json_job_wrapper)\n",
    "\n",
    "with open(educationWrapperFile) as json_edu_wrapper:\n",
    "    educationWrapper = json.load(json_edu_wrapper)\n",
    "    \n",
    "print({k:jobWrapper[k] for k in list(jobWrapper.keys())[:2]})\n",
    "print({k:educationWrapper[k] for k in list(educationWrapper.keys())[:2]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As i anticipated previously, since education and job fields fetched from linkedin html pages could have entered with different naming even though they could be identified with a single category, i decided to compute some basic remapping. By the way in order to have a more clean and meaningful dataset to inspect i decided to map semantically similar jobs or degrees under one same branch. To clarify, for each profile whose work experience was Developer, Web Developer, Sviluppatore software and so on, i mapped those field under the same keyword Sviluppatore. In order to do so i wrapped into two json files key value pairs where i linked a list of synonims under a unique key. in the cell above it is wrapped the code through which i incapsulated the contents of those two files in two dictionaries whose two first elements i showcased to give a glimpse of the fields.        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inList(array , dictionary):\n",
    "    for lval in array:\n",
    "        for key, val in dictionary.items():\n",
    "               for v in val:\n",
    "                    if v in lval:\n",
    "                          return key\n",
    "                        \n",
    "def calcGraduationYears(degInfo, dateRanges):\n",
    "    if dateRanges[0] < dateRanges[1]:\n",
    "        return int(dateRanges[1])\n",
    "    else:\n",
    "        if degInfo == 'Triennale' or degInfo == 'Dottorato':\n",
    "            return int(dateRanges[0]) + 3\n",
    "        else:\n",
    "            return int(dateRanges[0]) + 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "what comes then is the definition of another basic function other than inList that i already described which is the calcGraduationYears. the function basically watches if there are some missing graduationFields (given by the fact that the candidate is still studying to graduate) and infers them from the enrollment years by adding the expected time to graduate depending on the type of graduation.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "from functools import partial\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "df1 = df\n",
    "\n",
    "mappedJobs = list(map(partial(inList, dictionary=jobWrapper), df1.Job))\n",
    "mappedEdus = list(map(partial(inList, dictionary=educationWrapper), df1.Education))\n",
    "\n",
    "\n",
    "df1['Job'] = mappedJobs\n",
    "df1['Education'] = mappedEdus\n",
    "\n",
    "df2 = df1[df1.dateRange.map(len) > 1]\n",
    "\n",
    "enrollmentYears = [int(yearRange[0]) for yearRange in df2.dateRange]\n",
    "graduationYears = list(map(calcGraduationYears, df2.infoDeg , df2.dateRange))\n",
    "\n",
    "df3 = df2\n",
    "\n",
    "df3.drop('dateRange', axis = 1, inplace= True)\n",
    "df3['enrollmentYears'] = enrollmentYears\n",
    "df3['graduationYears'] = graduationYears"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "once the values are mapped i built another dataset switching the old values with the new ones whose first rows are showed in the following cells. After this small processing the dataset, fullfilled with more meaningful and easy-to-read data is ready to be scanned to get the first insights.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job                object\n",
      "Education          object\n",
      "infoDeg            object\n",
      "enrollmentYears     int64\n",
      "graduationYears     int64\n",
      "dtype: object\n",
      "(427, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job</th>\n",
       "      <th>Education</th>\n",
       "      <th>infoDeg</th>\n",
       "      <th>enrollmentYears</th>\n",
       "      <th>graduationYears</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Risorse umane</td>\n",
       "      <td>Giurisprudenza</td>\n",
       "      <td>Magistrale</td>\n",
       "      <td>2015</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ristorazione</td>\n",
       "      <td>Scienze politiche</td>\n",
       "      <td>Triennale</td>\n",
       "      <td>2014</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Insegnante</td>\n",
       "      <td>Lettere e Filosofia</td>\n",
       "      <td>Magistrale</td>\n",
       "      <td>2017</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sviluppatore</td>\n",
       "      <td>Ingegneria Informatica</td>\n",
       "      <td>Triennale</td>\n",
       "      <td>2016</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sviluppatore</td>\n",
       "      <td>Ingegneria Informatica</td>\n",
       "      <td>Magistrale</td>\n",
       "      <td>2019</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>Insegnante</td>\n",
       "      <td>Lettere e Filosofia</td>\n",
       "      <td>Triennale</td>\n",
       "      <td>2005</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>Insegnante</td>\n",
       "      <td>Lettere e Filosofia</td>\n",
       "      <td>Magistrale</td>\n",
       "      <td>2019</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>Insegnante</td>\n",
       "      <td>Lettere e Filosofia</td>\n",
       "      <td>Triennale</td>\n",
       "      <td>1998</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>Insegnante</td>\n",
       "      <td>Lettere e Filosofia</td>\n",
       "      <td>Magistrale</td>\n",
       "      <td>2019</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>Ricercatore</td>\n",
       "      <td>Lettere e Filosofia</td>\n",
       "      <td>Triennale</td>\n",
       "      <td>1991</td>\n",
       "      <td>1996</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>427 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Job               Education     infoDeg  enrollmentYears  \\\n",
       "0    Risorse umane          Giurisprudenza  Magistrale             2015   \n",
       "1     Ristorazione       Scienze politiche   Triennale             2014   \n",
       "2       Insegnante     Lettere e Filosofia  Magistrale             2017   \n",
       "3     Sviluppatore  Ingegneria Informatica   Triennale             2016   \n",
       "4     Sviluppatore  Ingegneria Informatica  Magistrale             2019   \n",
       "..             ...                     ...         ...              ...   \n",
       "489     Insegnante     Lettere e Filosofia   Triennale             2005   \n",
       "490     Insegnante     Lettere e Filosofia  Magistrale             2019   \n",
       "492     Insegnante     Lettere e Filosofia   Triennale             1998   \n",
       "493     Insegnante     Lettere e Filosofia  Magistrale             2019   \n",
       "494    Ricercatore     Lettere e Filosofia   Triennale             1991   \n",
       "\n",
       "     graduationYears  \n",
       "0               2017  \n",
       "1               2016  \n",
       "2               2020  \n",
       "3               2021  \n",
       "4               2020  \n",
       "..               ...  \n",
       "489             2009  \n",
       "490             2021  \n",
       "492             2010  \n",
       "493             2021  \n",
       "494             1996  \n",
       "\n",
       "[427 rows x 5 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.dropna(inplace=True)\n",
    "\n",
    "print(df3.dtypes)\n",
    "print(df3.shape)\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.to_csv('out.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas_profiling import ProfileReport\n",
    "\n",
    "df3.reset_index(drop = True,inplace=True)\n",
    "\n",
    "profile = ProfileReport(df3,missing_diagrams={'bar':False,'matrix':False,'heatmap':False,'dendrogram':False})\n",
    "profile.to_file(\"report.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the chunck of code above in order to display a rapresentation of the report of the data as fancy as possible i used the pandas-profiling module in order to save it in a html file. Basically what it does is to provide a more enriched rappresentation of the API describe() from pandas which is used as well to generate some descriptive statistics about the features of the dataset to give some insights about it, and it calculates how correlated the features are.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
