{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import csv\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "files = os.listdir(\".\")\n",
    "\n",
    "experiences = []\n",
    "educations = []\n",
    "\n",
    "profiles = []\n",
    "\n",
    "tag = ['h3', 'span']\n",
    "classes = ['education__item education__item--degree-info','pv-entity__comma-item','pv-entity__school-name t-16 t-black t-bold', 't-16 t-black t-bold','profile-section-card__title']\n",
    "\n",
    "\n",
    "for f in files:\n",
    "    if f.endswith(\".html\"):\n",
    "        with open(f, encoding='utf-8') as fp:\n",
    "            soup = BeautifulSoup(fp)\n",
    "            regex = re.compile('.*experience.*')\n",
    "            experienceSection = soup.find('section', {'class':regex})\n",
    "            for el in experienceSection.find_all('span', {'class':'visually-hidden'}): el.decompose()\n",
    "            experienceTags = (experienceSection.find_all(t, {'class': c}) for t in tag for c in classes)\n",
    "            expText = next((exp for exp in experienceTags if len(exp) > 0), \"\")\n",
    "            experience = [el.get_text().strip() for el in expText if el != \"\"]\n",
    "            regexEd = re.compile('.*education.*')\n",
    "            educationSection = soup.find('section', {'class':regexEd})\n",
    "            educationTags = (educationSection.find_all(tag[1], {'class':c}) for c in classes)\n",
    "            edText = next((ed for ed in educationTags if len(ed) > 0), \"\")\n",
    "            education = [el.get_text().strip() for el in edText if el != \"\"]\n",
    "            profiles.append([experience, education])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this first huge part of code above i built a scraper almost from scratch using Beautiful Soup which is a python library i used to pull out data from the html files of linkedin profiles i manually downloaded in the current local directory. In a nutshell what i did was looping over almost 500 profiles pages donwloaded from LinkedIn and for each file i extracted those element of interest in order to fatch data from education and work section. In order to do that i queried the significant html element by tag name and class name saving the text data i needed into a list of lists in order to save them into a csv file for persistency and then loading them into pandas df for the manipulation.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loggin into a .csv file\n",
    "\n",
    "import csv\n",
    "\n",
    "header = ['Job','Education']\n",
    "\n",
    "csv_file = 'linkedin_profiles.csv'\n",
    "with open(csv_file, 'w', newline='') as fp:\n",
    "    writer = csv.writer(fp)\n",
    "    writer.writerow(header)\n",
    "    writer.writerows(profiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job</th>\n",
       "      <th>Education</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['Training Specialist', 'Training Specialist',...</td>\n",
       "      <td>['Master di I livello', 'Politiche di Sicurezz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[\"Esperienze di Lavoro all'Estero come Care As...</td>\n",
       "      <td>['Scienze Politiche,Sociali ed Internazionali'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['docente di lettere', 'docente di lettere', '...</td>\n",
       "      <td>['Laurea Magistrale  LM in Scienze Umanistiche...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['Junior Software Developer', 'Promoter vendit...</td>\n",
       "      <td>['Laurea triennale', 'Ingegneria informatica',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['IoT Edge Developer', 'Sviluppatore front-end']</td>\n",
       "      <td>['Laurea Magistrale  LM', 'Ingegneria informat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Job  \\\n",
       "0  ['Training Specialist', 'Training Specialist',...   \n",
       "1  [\"Esperienze di Lavoro all'Estero come Care As...   \n",
       "2  ['docente di lettere', 'docente di lettere', '...   \n",
       "3  ['Junior Software Developer', 'Promoter vendit...   \n",
       "4   ['IoT Edge Developer', 'Sviluppatore front-end']   \n",
       "\n",
       "                                           Education  \n",
       "0  ['Master di I livello', 'Politiche di Sicurezz...  \n",
       "1  ['Scienze Politiche,Sociali ed Internazionali'...  \n",
       "2  ['Laurea Magistrale  LM in Scienze Umanistiche...  \n",
       "3  ['Laurea triennale', 'Ingegneria informatica',...  \n",
       "4  ['Laurea Magistrale  LM', 'Ingegneria informat...  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reporting data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('linkedin_profiles.csv', encoding='ISO-8859-1')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Job          object\n",
       "Education    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the dataset, whose first elements are showcased by the head() method of pandas library, does still contain data that are a bit raw. Given that, the two columns displayed incapsulate inside lists all of those data scraped from html pages of linkedin profile such as all jobs registered in the experience section and all education information that could go from high school to P.h.d degrees. From this first sight at data it appears to me that this dataset needs to be modified a bit in order to keep just the information of interest for this work such as education titles involving just bachelor or master degrees from University of Bologna and the last job inserted in the list of jobs, since the aim is to understand which job is most likely to be done by people with a specific degree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(496, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from ast import literal_eval\n",
    "\n",
    "df.Job = df.Job.apply(literal_eval)\n",
    "df.Education = df.Education.apply(literal_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in the cell above, since data fetched from the csv file containing linkedin profiles previously stored in arrays are perceived as one big string i applied a function in order to split those string back into the two lists of job and education, whilst in the cell below i noticed from the csv file that there were some fields with valued marked as empty lists thus i got rid of them.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job</th>\n",
       "      <th>Education</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Training Specialist, Training Specialist, Leg...</td>\n",
       "      <td>[Master di I livello, Politiche di Sicurezza e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Esperienze di Lavoro all'Estero come Care Ass...</td>\n",
       "      <td>[Scienze Politiche,Sociali ed Internazionali, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[docente di lettere, docente di lettere, docen...</td>\n",
       "      <td>[Laurea Magistrale  LM in Scienze Umanistiche,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Junior Software Developer, Promoter vendite, ...</td>\n",
       "      <td>[Laurea triennale, Ingegneria informatica, 86/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[IoT Edge Developer, Sviluppatore front-end]</td>\n",
       "      <td>[Laurea Magistrale  LM, Ingegneria informatica...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>[Professore di Archeologia del Paesaggio, Ph.D...</td>\n",
       "      <td>[Master, Bioarcheologia, Paleopatologia Antrop...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>[Insegnante di lettere miur, Coworker logistic...</td>\n",
       "      <td>[laurea quadriennale in lettere moderne, lette...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>[Tutor privato]</td>\n",
       "      <td>[Laurea Magistrale  LM, Filologia classica, 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>[Ricercatore]</td>\n",
       "      <td>[1° ciclo -  Laurea L, storia dei Paesi Afrosi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>[Conduttrice radiofonica, Giornalista]</td>\n",
       "      <td>[Laurea in Lettere Moderne, 110/lode, Laurea i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>493 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Job  \\\n",
       "0    [Training Specialist, Training Specialist, Leg...   \n",
       "1    [Esperienze di Lavoro all'Estero come Care Ass...   \n",
       "2    [docente di lettere, docente di lettere, docen...   \n",
       "3    [Junior Software Developer, Promoter vendite, ...   \n",
       "4         [IoT Edge Developer, Sviluppatore front-end]   \n",
       "..                                                 ...   \n",
       "491  [Professore di Archeologia del Paesaggio, Ph.D...   \n",
       "492  [Insegnante di lettere miur, Coworker logistic...   \n",
       "493                                    [Tutor privato]   \n",
       "494                                      [Ricercatore]   \n",
       "495             [Conduttrice radiofonica, Giornalista]   \n",
       "\n",
       "                                             Education  \n",
       "0    [Master di I livello, Politiche di Sicurezza e...  \n",
       "1    [Scienze Politiche,Sociali ed Internazionali, ...  \n",
       "2    [Laurea Magistrale  LM in Scienze Umanistiche,...  \n",
       "3    [Laurea triennale, Ingegneria informatica, 86/...  \n",
       "4    [Laurea Magistrale  LM, Ingegneria informatica...  \n",
       "..                                                 ...  \n",
       "491  [Master, Bioarcheologia, Paleopatologia Antrop...  \n",
       "492  [laurea quadriennale in lettere moderne, lette...  \n",
       "493  [Laurea Magistrale  LM, Filologia classica, 11...  \n",
       "494  [1° ciclo -  Laurea L, storia dei Paesi Afrosi...  \n",
       "495  [Laurea in Lettere Moderne, 110/lode, Laurea i...  \n",
       "\n",
       "[493 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n",
    "\n",
    "df1 = df[df.Education.map(len) > 0]\n",
    "df1.reset_index()\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Risorse umane': ['Responsabile Area Espansione', 'Senior Recruitment Officer', 'Analista Direzione Sviluppo Persone e Organizzazione', 'Training Specialist', 'HR'], 'Ristorazione': ['Assistente enologo', 'Barman', 'barista']}\n",
      "{'Giurisprudenza': ['Giurisprudenza'], 'Scienze della comunicazione': ['Semiotica', 'Marketing', 'PubblicitÃ\\xa0', 'Communication', 'Comunicazione', 'comunicazione', \"comunicazione pubblica, d'impresa e pubblicitÃ\\xa0\", 'Mass media e Politica', 'Brand Strategy and Marketing', 'Scienze della comunicazione', 'Comunicazione e Digital Media', 'Scienze della Comunicazione', 'Comunicazione']}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "jobWrapperFile = 'jobWrapper.json'\n",
    "educationWrapperFile = 'educationWrapper.json'\n",
    "\n",
    "jobWrapper = {}\n",
    "educationWrapper = {} \n",
    "\n",
    "with open(jobWrapperFile) as json_job_wrapper:\n",
    "    jobWrapper = json.load(json_job_wrapper)\n",
    "\n",
    "with open(educationWrapperFile) as json_edu_wrapper:\n",
    "    educationWrapper = json.load(json_edu_wrapper)\n",
    "    \n",
    "print({k:jobWrapper[k] for k in list(jobWrapper.keys())[:2]})\n",
    "print({k:educationWrapper[k] for k in list(educationWrapper.keys())[:2]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As i anticipated previously, since education and job fields fetched from linkedin html pages could have entered with different naming even though they could be identified with a single category, i decided to compute some basic remapping. By the way in order to have a more clean and meaningful dataset to inspect i decided to map semantically similar jobs or degrees under one same branch. To clarify, for each profile whose work experience was Developer, Web Developer, Sviluppatore software and so on, i mapped those field under the same keyword Sviluppatore. In order to do so i wrapped into two json files key value pairs where i linked a list of synonims under a unique key. in the cell above it is wrapped the code through which i incapsulated the contents of those two files in two dictionaries whose two first elements i showcased to give a glimpse of the fields.        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inList(array , dictionary):\n",
    "    for lval in array:\n",
    "        for key, val in dictionary.items():\n",
    "               for v in val:\n",
    "                    if v in lval:\n",
    "                          return key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "what comes then is the definition of a basic function looping over the element of the array in jobs and educations and over the key and values in the dictionaries checking if one the values of the dictionary is contained in the lists of jobs and educations thus returning the key associated.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from functools import partial\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "mappedJobs = list(map(partial(inList, dictionary=jobWrapper), df1.Job))\n",
    "mappedEdus = list(map(partial(inList, dictionary=educationWrapper), df1.Education))\n",
    "\n",
    "df2 = df1\n",
    "df2['Job'] = mappedJobs\n",
    "df2['Education'] = mappedEdus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "once the values are mapped i built another dataset switching the old values with the new ones whose first rows are showed in the following cells. After this small processing the dataset, fullfilled with more meaningful and easy-to-read data is ready to be scanned to get the first insights.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job</th>\n",
       "      <th>Education</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Risorse umane</td>\n",
       "      <td>Giurisprudenza</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ristorazione</td>\n",
       "      <td>Scienze politiche</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Insegnante</td>\n",
       "      <td>Lettere e Filosofia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sviluppatore</td>\n",
       "      <td>Ingegneria Informatica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sviluppatore</td>\n",
       "      <td>Ingegneria Informatica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Job               Education\n",
       "0  Risorse umane          Giurisprudenza\n",
       "1   Ristorazione       Scienze politiche\n",
       "2     Insegnante     Lettere e Filosofia\n",
       "3   Sviluppatore  Ingegneria Informatica\n",
       "4   Sviluppatore  Ingegneria Informatica"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas_profiling import ProfileReport\n",
    "\n",
    "df2.reset_index(drop = True,inplace=True)\n",
    "\n",
    "profile = ProfileReport(df2,missing_diagrams={'bar':False,'matrix':False,'heatmap':False,'dendrogram':False})\n",
    "profile.to_file(\"report.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the chunck of code above in order to display a rapresentation of the report of the data as fancy as possible i used the pandas-profiling module in order to save it in a html file. Basically what it does is to provide a more enriched rappresentation of the API describe() from pandas which is used as well to generate some descriptive statistics about the features of the dataset to give some insights about it. As shown above, the domain of the features of the dataset is the one of nominal data thus involving description about frequency, the most common value printed by the top metric including also first and last values alongside with a count of the value of the features. Other than that there are also some metrics about how data are correlated exploiting for example Cramer's V as a measure of association beetween the two nominal features involved. The graph also gives a glimpse of missing data and a sample of the dataset.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
